{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "###       SET UP LOGGER        ###\n",
    "##################################\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='logs.txt',\n",
    "                    filemode='a',\n",
    "                    format=\"%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s\",\n",
    "                    datefmt=\"%H:%M:%S\",\n",
    "                    level=logging.DEBUG)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "###       DEPENDENCIES         ###\n",
    "##################################\n",
    "\n",
    "# general\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "# H20 GPT client\n",
    "import ast\n",
    "import gradio_client\n",
    "\n",
    "# FHIR client\n",
    "from fhirclient.client import FHIRClient\n",
    "from fhirclient.models.observation import Observation\n",
    "from fhirclient.models.condition import Condition\n",
    "from fhirclient.models.medicationstatement import MedicationStatement\n",
    "from fhirclient.models.medication import Medication\n",
    "from fhirclient.models.procedure import Procedure\n",
    "from fhirclient.models.annotation import Annotation\n",
    "from fhirclient.models.patient import Patient\n",
    "\n",
    "# EBI client (ontology)\n",
    "from ols_client import EBIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: http://localhost:7860/ âœ”\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "###       SET UP               ###\n",
    "##################################\n",
    "\n",
    "# get the config\n",
    "with open(\"config.yml\", \"r\") as ymlfile:\n",
    "    config = yaml.safe_load(ymlfile)\n",
    "\n",
    "# FHIR client settings\n",
    "fhir_settings = {\n",
    "    \"app_id\": config[\"FHIR\"][\"app_id\"],\n",
    "    \"api_base\": config[\"FHIR\"][\"api_base\"],\n",
    "}\n",
    "fhir_client = FHIRClient(settings=fhir_settings)\n",
    "\n",
    "# set up H2O GPT client\n",
    "llm_client = gradio_client.Client(config[\"H2O\"][\"HOST_URL\"])\n",
    "logger.info(\"H2O GPT client set up\")\n",
    "\n",
    "# set up EBI client\n",
    "ebi_client = EBIClient()\n",
    "\n",
    "# get test data\n",
    "data = pd.read_csv(config[\"DATA\"][\"path\"], sep=config[\"DATA\"][\"sep\"])\n",
    "logger.info(\"Test data on {} paients loaded\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "###     UPLOAD PATIENTS        ###\n",
    "##################################\n",
    "\n",
    "# create a patient\n",
    "patient = Patient({\n",
    "    \"name\": [{\"text\": \"John Dae\"}]\n",
    "})\n",
    "patient.create(fhir_client.server)\n",
    "\n",
    "# create a medication\n",
    "medication = Medication({\n",
    "    \"status\": \"active\"\n",
    "})\n",
    "medication.create(fhir_client.server)\n",
    "\n",
    "# convert each observation to FHIR and write to the FHIR server\n",
    "# as a preliminary observation linked to the patient John Dae\n",
    "for ind, raw in data.iterrows():\n",
    "    observation = Observation({\n",
    "        \"status\": \"registered\",\n",
    "        \"code\": {\"text\": data.iloc[ind,1]},\n",
    "        \"subject\": {\n",
    "            \"reference\": \"Patient/1\",\n",
    "            \"display\": \"John Dae\"\n",
    "        },\n",
    "    })\n",
    "    observation.create(fhir_client.server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error:  for url: http://localhost:8080/fhir/Procedure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 264\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m \n\u001b[1;32m    262\u001b[0m     \u001b[39m# annotate the batch of observations\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[39mfor\u001b[39;00m observation \u001b[39min\u001b[39;00m observations:\n\u001b[0;32m--> 264\u001b[0m         annotate_observation(observation, local_fhir_client, note_id, update \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    265\u001b[0m         note_id \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[12], line 228\u001b[0m, in \u001b[0;36mannotate_observation\u001b[0;34m(observation, fhir_client, note_id, update)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[39m# write the procedure\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         procedure \u001b[39m=\u001b[39m Procedure({\n\u001b[1;32m    217\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpreliminary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    218\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39mcoding\u001b[39m\u001b[39m\"\u001b[39m: [procedure_json[\u001b[39m\"\u001b[39m\u001b[39mcoding\u001b[39m\u001b[39m\"\u001b[39m]]},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m             }]\n\u001b[1;32m    227\u001b[0m         })\n\u001b[0;32m--> 228\u001b[0m         procedure\u001b[39m.\u001b[39;49mcreate(fhir_client\u001b[39m.\u001b[39;49mserver)\n\u001b[1;32m    230\u001b[0m \u001b[39mreturn\u001b[39;00m ann_dict\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/gpt/lib/python3.11/site-packages/fhirclient/models/fhirabstractresource.py:127\u001b[0m, in \u001b[0;36mFHIRAbstractResource.create\u001b[0;34m(self, server)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid:\n\u001b[1;32m    125\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThis resource already has an id, cannot create\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m ret \u001b[39m=\u001b[39m srv\u001b[39m.\u001b[39;49mpost_json(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelativeBase(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mas_json())\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ret\u001b[39m.\u001b[39mtext) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/gpt/lib/python3.11/site-packages/fhirclient/server.py:248\u001b[0m, in \u001b[0;36mFHIRServer.post_json\u001b[0;34m(self, path, resource_json, nosign)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39m# perform the request but intercept 401 responses, raising our own Exception\u001b[39;00m\n\u001b[1;32m    247\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mpost(url, headers\u001b[39m=\u001b[39mheaders, data\u001b[39m=\u001b[39mjson\u001b[39m.\u001b[39mdumps(resource_json))\n\u001b[0;32m--> 248\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraise_for_status(res)\n\u001b[1;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/gpt/lib/python3.11/site-packages/fhirclient/server.py:299\u001b[0m, in \u001b[0;36mFHIRServer.raise_for_status\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[39mraise\u001b[39;00m FHIRNotFoundException(response)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/gpt/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Server Error: \u001b[39m\u001b[39m{\u001b[39;00mreason\u001b[39m}\u001b[39;00m\u001b[39m for url: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error:  for url: http://localhost:8080/fhir/Procedure"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "###   EXTRACT DATA USING LLM   ###\n",
    "##################################\n",
    "\n",
    "# llm call function\n",
    "def run_llm(prompt):\n",
    "\n",
    "    # string of dict for input\n",
    "    kwargs = dict(instruction_nochat=prompt)\n",
    "\n",
    "    # run LLM\n",
    "    logger.info(f\"Prompt: {prompt}\")\n",
    "    res = llm_client.predict(str(dict(kwargs)), api_name=\"/submit_nochat_api\")\n",
    "    \n",
    "    # extract response\n",
    "    response = ast.literal_eval(res)[\"response\"]\n",
    "    logger.info(f\"Response: {response}\")\n",
    "    return response\n",
    "\n",
    "# get the prompt for the given template\n",
    "def get_completion_prompt(text, config = config):\n",
    "    \"\"\"Get the prompt for the given template.\"\"\"\n",
    "\n",
    "    # concatinate the prompt with doctor\"s note\n",
    "    prompt = config[\"LLM\"][\"system_prompt\"] + text\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# process LLM response\n",
    "def process_llm_response(ann_text):\n",
    "    \n",
    "    # process response string\n",
    "    ann_text = ann_text.strip() # strip\n",
    "    ann_text = ann_text.lower() # lower\n",
    "    ann_text = ann_text[ann_text.find(\"conditions\"):] # delete intro\n",
    "    ann_text = ann_text.replace(\"*\",\";\") # remove stars\n",
    "    ann_text = ann_text.replace(\"\\n\",\" \") # remove new lines\n",
    "    # add new lines to sections\n",
    "    ann_text = ann_text.replace(\"observations:\",\"\\nobservations:\")\n",
    "    ann_text = ann_text.replace(\"medications:\",\"\\nmedications:\")\n",
    "    ann_text = ann_text.replace(\"procedures:\",\"\\nprocedures:\")\n",
    "\n",
    "    # check that annotations has exactly 4 lines\n",
    "    anns = ann_text.split(\"\\n\")\n",
    "    if len(anns) != 4:\n",
    "        logger.error(\"The response not 4 lines\")\n",
    "        return None\n",
    "        \n",
    "    # convert to dict\n",
    "    ann_dict = {}\n",
    "    for ann in anns:\n",
    "\n",
    "        # split the key and value\n",
    "        ann_key, ann_values = ann.split(\":\", 1)\n",
    "\n",
    "        # split the value into a list\n",
    "        ann_values = [a.strip() for a in ann_values.strip().split(\";\") if a != \"\"]\n",
    "\n",
    "        # if there is an ignore phrase, reject the value\n",
    "        for ignore_phrase in config[\"LLM\"][\"ignore_phrases\"]:\n",
    "            ann_values = [a for a in ann_values if ignore_phrase not in a]\n",
    "\n",
    "        # extract entity and parameter from each value\n",
    "        value_dicts = []\n",
    "        for i in range(len(ann_values)):\n",
    "\n",
    "            # regular expression to find if there are brackets with parameters as in \"entity (parameter)\"\n",
    "            m = re.search(r\"\\(([A-Za-z0-9._\\-\\/ ]+)\\)\", ann_values[i])\n",
    "\n",
    "            # if there is a match, extract the entity and parameter\n",
    "            if m is not None and ann_key in config[\"LLM\"][\"headers_with_parameters\"]:\n",
    "\n",
    "                # extract the entity from the value\n",
    "                entity = ann_values[i][:m.span()[0]].strip()\n",
    "                parameter = m.group(1).strip()\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # otherwise the entity is the whole value and the parameter is empty\n",
    "                entity = ann_values[i].strip(),\n",
    "                parameter = \"\"\n",
    "        \n",
    "            # if entity is tuple, convert to string\n",
    "            if type(entity) == tuple:\n",
    "                entity = entity[0]\n",
    "\n",
    "            # ground the entity in ontology\n",
    "            ontology = annotate_term_with_ontology(entity)\n",
    "\n",
    "            # define the value dictionary with entity, parameter and ontology only if ontology was detected\n",
    "            if ontology is not None:\n",
    "                value_dicts.append({\n",
    "                    \"entity\": entity,\n",
    "                    \"parameter\": parameter,\n",
    "                    \"coding\": ontology\n",
    "                })\n",
    "\n",
    "        # write to the dict\n",
    "        ann_dict[ann_key] = value_dicts\n",
    "\n",
    "    # check that annotation dict has each of the expected headers \n",
    "    for i in range(4):\n",
    "        if config[\"LLM\"][\"headers\"][i] not in ann_dict.keys():\n",
    "            logger.error(\"The response does not start with the correct header\")\n",
    "            return None\n",
    "\n",
    "    return ann_dict\n",
    "\n",
    "# annotate observation\n",
    "def annotate_observation(observation, fhir_client, note_id, update = True):\n",
    "    \n",
    "    # generate the prompt\n",
    "    prompt = get_completion_prompt(\n",
    "        text = observation.code.text\n",
    "    )\n",
    "    \n",
    "    # LLM call to extract entities \n",
    "    ann_text = run_llm(prompt)\n",
    "\n",
    "    # preprocess annotation text\n",
    "    ann_dict = process_llm_response(ann_text)\n",
    "\n",
    "    # update FHIR records\n",
    "    if update:\n",
    "\n",
    "        # update the observation\n",
    "        observation.note = [Annotation({\n",
    "            \"authorString\" : \"Raw annotations from LLama2\",\n",
    "            \"text\": str(ann_dict)\n",
    "        })]\n",
    "        observation.status = \"final\"\n",
    "        observation.update(fhir_client.server)\n",
    "\n",
    "        # write derived conditions\n",
    "        for ind, condition_json in enumerate(ann_dict[\"conditions\"]):\n",
    "            \n",
    "            # add unique note id and processing id\n",
    "            condition_json['note_id'] = note_id\n",
    "            condition_json['condition_id'] = ind\n",
    "            \n",
    "            # write the condition\n",
    "            condition = Condition({\n",
    "                \"clinicalStatus\": {\"text\": \"preliminary\"},\n",
    "                \"code\": {\"coding\": [condition_json[\"coding\"]]},\n",
    "                \"subject\": {\n",
    "                    \"reference\": \"Patient/1\",\n",
    "                    \"display\": \"John Dae\"\n",
    "                },\n",
    "                \"note\": [{\n",
    "                    \"authorString\" : \"Raw annotations from LLama2\",\n",
    "                    \"text\": str(condition_json)\n",
    "                }]\n",
    "            })\n",
    "            condition.create(fhir_client.server)\n",
    "\n",
    "        # write derived observations\n",
    "        for ind, observation_json in enumerate(ann_dict[\"observations\"]):\n",
    "            \n",
    "            # add unique note id and processing id\n",
    "            observation_json['note_id'] = note_id\n",
    "            observation_json['observation_id'] = ind\n",
    "            \n",
    "            # write the observation\n",
    "            observation = Observation({\n",
    "                \"status\": \"preliminary\",\n",
    "                \"code\": {\"coding\": [observation_json[\"coding\"]]},\n",
    "                \"valueString\": observation_json[\"parameter\"],\n",
    "                \"subject\": {\n",
    "                    \"reference\": \"Patient/1\",\n",
    "                    \"display\": \"John Dae\"\n",
    "                },\n",
    "                \"note\": [{\n",
    "                    \"authorString\" : \"Raw annotations from LLama2\",\n",
    "                    \"text\": str(observation_json)\n",
    "                }]\n",
    "            })\n",
    "            observation.create(fhir_client.server)\n",
    "\n",
    "        # write derived conditions\n",
    "        for ind, medication_json in enumerate(ann_dict[\"medications\"]):\n",
    "            \n",
    "            # add unique note id and processing id\n",
    "            medication_json['note_id'] = note_id\n",
    "            medication_json['medication_id'] = ind\n",
    "\n",
    "            # write the medication\n",
    "            medication = MedicationStatement({\n",
    "                \"status\": \"preliminary\",\n",
    "                \"category\": {\"coding\": [medication_json[\"coding\"]]},\n",
    "                \"medication\": {\n",
    "                    \"reference\": \"Medication/2\",\n",
    "                    \"display\": medication_json[\"entity\"]\n",
    "                },\n",
    "                \"dosage\": [{\n",
    "                    \"text\": medication_json[\"parameter\"]\n",
    "                }],\n",
    "                \"subject\": {\n",
    "                    \"reference\": \"Patient/1\",\n",
    "                    \"display\": \"John Dae\"\n",
    "                },\n",
    "                \"note\": [{\n",
    "                    \"authorString\" : \"Raw annotations from LLama2\",\n",
    "                    \"text\": str(medication_json)\n",
    "                }]\n",
    "            })\n",
    "            medication.create(fhir_client.server)\n",
    "\n",
    "        # write derived conditions\n",
    "        for ind, procedure_json in enumerate(ann_dict[\"procedures\"]):\n",
    "\n",
    "            # add unique note id and processing id\n",
    "            procedure_json['note_id'] = note_id\n",
    "            procedure_json['procedure_id'] = ind\n",
    "\n",
    "            # write the procedure\n",
    "            procedure = Procedure({\n",
    "                \"status\": \"preliminary\",\n",
    "                \"code\": {\"coding\": [procedure_json[\"coding\"]]},\n",
    "                \"subject\": {\n",
    "                    \"reference\": \"Patient/1\",\n",
    "                    \"display\": \"John Dae\"\n",
    "                },\n",
    "                \"note\": [{\n",
    "                    \"authorString\": \"Raw annotations from LLama2\",\n",
    "                    \"text\": str(procedure_json)\n",
    "                }]\n",
    "            })\n",
    "            procedure.create(fhir_client.server)\n",
    "\n",
    "    return ann_dict\n",
    "\n",
    "# annotate using ontology\n",
    "def annotate_term_with_ontology(text):\n",
    "    try:\n",
    "        results = ebi_client.search(text)\n",
    "        if len(results) > 0:\n",
    "            return {\n",
    "                \"system\": results[0][\"iri\"],\n",
    "                \"code\": results[0][\"short_form\"],\n",
    "                \"display\": results[0][\"description\"][0]\n",
    "            }\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# annotate clinical notes\n",
    "job_not_done = True\n",
    "note_id = 0\n",
    "while job_not_done:\n",
    "\n",
    "    # get observation batch\n",
    "    local_fhir_client = FHIRClient(settings=fhir_settings)\n",
    "    search = Observation.where(struct={'status': 'registered'})\n",
    "    observations = search.perform_resources(local_fhir_client.server)\n",
    "\n",
    "    # check that it is not empty (job not finished)\n",
    "    if len(observations) == 0:\n",
    "        job_not_done = False\n",
    "    else:\n",
    "\n",
    "        # annotate the batch of observations\n",
    "        for observation in observations:\n",
    "            annotate_observation(observation, local_fhir_client, note_id, update = True)\n",
    "            note_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
